{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3f625b6f1344c3a9b3aadf438ac7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6f1b41e1544230a9bac11a021f61ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d67a4a339cc437c864b8bae9eb5ba2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786d56e6fc5441c9a62396f91530fe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xmod to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7317aebad4464a278abe3af1d4a977ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/610M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The state dictionary of the model you are trying to load is corrupted. Are you sure it was properly saved?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alber\\Desktop\\Onix\\test-bert-model.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alber/Desktop/Onix/test-bert-model.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mZurichNLP/swissbert-ner\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Desktop/Onix/test-bert-model.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alber/Desktop/Onix/test-bert-model.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m BertForTokenClassification\u001b[39m.\u001b[39;49mfrom_pretrained(model_name)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\modeling_utils.py:3175\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3165\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3166\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3168\u001b[0m     (\n\u001b[0;32m   3169\u001b[0m         model,\n\u001b[0;32m   3170\u001b[0m         missing_keys,\n\u001b[0;32m   3171\u001b[0m         unexpected_keys,\n\u001b[0;32m   3172\u001b[0m         mismatched_keys,\n\u001b[0;32m   3173\u001b[0m         offload_index,\n\u001b[0;32m   3174\u001b[0m         error_msgs,\n\u001b[1;32m-> 3175\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[0;32m   3176\u001b[0m         model,\n\u001b[0;32m   3177\u001b[0m         state_dict,\n\u001b[0;32m   3178\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3179\u001b[0m         resolved_archive_file,\n\u001b[0;32m   3180\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   3181\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[0;32m   3182\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[0;32m   3183\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[0;32m   3184\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[0;32m   3185\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[0;32m   3186\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[0;32m   3187\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[0;32m   3188\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[0;32m   3189\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(\u001b[39mgetattr\u001b[39;49m(model, \u001b[39m\"\u001b[39;49m\u001b[39mquantization_method\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39m==\u001b[39;49m QuantizationMethod\u001b[39m.\u001b[39;49mBITS_AND_BYTES),\n\u001b[0;32m   3190\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[0;32m   3191\u001b[0m     )\n\u001b[0;32m   3193\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[0;32m   3194\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\modeling_utils.py:3444\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3442\u001b[0m base_model_expected_keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(model_to_load\u001b[39m.\u001b[39mstate_dict()\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m   3443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(key \u001b[39min\u001b[39;00m expected_keys_not_prefixed \u001b[39mand\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m base_model_expected_keys \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m loaded_keys):\n\u001b[1;32m-> 3444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3445\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe state dictionary of the model you are trying to load is corrupted. Are you sure it was \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mproperly saved?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3447\u001b[0m     )\n\u001b[0;32m   3448\u001b[0m \u001b[39mif\u001b[39;00m device_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3449\u001b[0m     device_map \u001b[39m=\u001b[39m {k\u001b[39m.\u001b[39mreplace(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbase_model_prefix\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m device_map\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[1;31mValueError\u001b[0m: The state dictionary of the model you are trying to load is corrupted. Are you sure it was properly saved?"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/tasks/token_classification\n",
    "# https://discuss.huggingface.co/t/decoding-the-predicted-output-array-in-distilbertbase-uncased-model-for-ner/10673\n",
    "\n",
    "from transformers import AutoTokenizer, BertForTokenClassification\n",
    "\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "# model_name = \"DunnBC22/bert-base-multilingual-cased-fine_tuned-ner-WikiNeural_Multilingual\"\n",
    "# model_name = \"ZurichNLP/swissbert-ner\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11590, 11324, 10124, 23438, 21115, 10111,   146, 12962, 10106,\n",
      "         22218,   117, 11621,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"My name is Alexandra Cook and I live in Berkeley, California.\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenClassifierOutput(loss=None, logits=tensor([[[10.6321, -2.0881, -1.0898, -2.2244, -1.6442, -2.6137, -1.8502,\n",
      "          -2.1623, -1.8636],\n",
      "         [11.6384, -1.8568, -2.3482, -2.1273, -2.2118, -2.4733, -2.5500,\n",
      "          -2.0165, -1.7881],\n",
      "         [11.7377, -2.4347, -1.8779, -2.2032, -1.5827, -2.9616, -1.8463,\n",
      "          -2.6302, -1.5406],\n",
      "         [11.8304, -2.2112, -2.0503, -2.1710, -1.7848, -2.5093, -1.8867,\n",
      "          -2.8236, -1.5834],\n",
      "         [-1.4116,  9.7755, -1.3339, -0.6484, -2.8207,  0.4549, -1.8275,\n",
      "          -0.5851, -1.5089],\n",
      "         [ 0.2990,  0.0870,  9.5672, -2.8546, -0.5908, -2.0112, -0.0644,\n",
      "          -2.1752, -0.6135],\n",
      "         [11.2450, -2.2434, -0.7249, -2.7106, -1.1764, -3.4705, -1.3048,\n",
      "          -2.8482, -1.5336],\n",
      "         [10.4234, -0.7049, -2.9397, -1.5334, -3.1458, -0.9478, -3.6194,\n",
      "          -1.0742, -2.0836],\n",
      "         [11.7996, -2.4407, -1.8579, -2.2174, -1.5323, -2.7359, -1.7890,\n",
      "          -2.7478, -1.7362],\n",
      "         [11.8186, -2.5249, -2.0083, -2.3016, -1.5187, -2.3220, -1.6336,\n",
      "          -3.0632, -1.5309],\n",
      "         [-1.8878, -0.4863, -2.3311,  0.9190, -1.8993,  9.9259, -1.6484,\n",
      "          -1.2756, -1.5844],\n",
      "         [11.4039, -2.7718, -1.0694, -2.8608, -1.1537, -2.9759, -0.6608,\n",
      "          -3.0989, -1.3015],\n",
      "         [-0.7199, -1.6638, -2.4418, -0.5009, -1.7564, 10.0552, -0.7959,\n",
      "          -1.3042, -1.2319],\n",
      "         [11.7472, -2.3103, -1.6647, -2.2101, -1.6755, -2.8884, -1.7445,\n",
      "          -2.6843, -1.8029],\n",
      "         [ 8.5971, -1.9641, -4.5843, -0.9008, -3.7497,  0.2388, -2.6292,\n",
      "           1.0785, -1.8112]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "outputs = model(**encoding)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10.6321, -2.0881, -1.0898, -2.2244, -1.6442, -2.6137, -1.8502,\n",
      "          -2.1623, -1.8636],\n",
      "         [11.6384, -1.8568, -2.3482, -2.1273, -2.2118, -2.4733, -2.5500,\n",
      "          -2.0165, -1.7881],\n",
      "         [11.7377, -2.4347, -1.8779, -2.2032, -1.5827, -2.9616, -1.8463,\n",
      "          -2.6302, -1.5406],\n",
      "         [11.8304, -2.2112, -2.0503, -2.1710, -1.7848, -2.5093, -1.8867,\n",
      "          -2.8236, -1.5834],\n",
      "         [-1.4116,  9.7755, -1.3339, -0.6484, -2.8207,  0.4549, -1.8275,\n",
      "          -0.5851, -1.5089],\n",
      "         [ 0.2990,  0.0870,  9.5672, -2.8546, -0.5908, -2.0112, -0.0644,\n",
      "          -2.1752, -0.6135],\n",
      "         [11.2450, -2.2434, -0.7249, -2.7106, -1.1764, -3.4705, -1.3048,\n",
      "          -2.8482, -1.5336],\n",
      "         [10.4234, -0.7049, -2.9397, -1.5334, -3.1458, -0.9478, -3.6194,\n",
      "          -1.0742, -2.0836],\n",
      "         [11.7996, -2.4407, -1.8579, -2.2174, -1.5323, -2.7359, -1.7890,\n",
      "          -2.7478, -1.7362],\n",
      "         [11.8186, -2.5249, -2.0083, -2.3016, -1.5187, -2.3220, -1.6336,\n",
      "          -3.0632, -1.5309],\n",
      "         [-1.8878, -0.4863, -2.3311,  0.9190, -1.8993,  9.9259, -1.6484,\n",
      "          -1.2756, -1.5844],\n",
      "         [11.4039, -2.7718, -1.0694, -2.8608, -1.1537, -2.9759, -0.6608,\n",
      "          -3.0989, -1.3015],\n",
      "         [-0.7199, -1.6638, -2.4418, -0.5009, -1.7564, 10.0552, -0.7959,\n",
      "          -1.3042, -1.2319],\n",
      "         [11.7472, -2.3103, -1.6647, -2.2101, -1.6755, -2.8884, -1.7445,\n",
      "          -2.6843, -1.8029],\n",
      "         [ 8.5971, -1.9641, -4.5843, -0.9008, -3.7497,  0.2388, -2.6292,\n",
      "           1.0785, -1.8112]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 15, 9])\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "predicted_label_classes = logits.argmax(-1)\n",
    "print(predicted_label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [model.config.id2label[id] for id in predicted_label_classes.squeeze().tolist()]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x00000174E29305C0>\n",
      "[CLS] O\n",
      "My O\n",
      "name O\n",
      "is O\n",
      "Alexandra B-PER\n",
      "Cook I-PER\n",
      "and O\n",
      "I O\n",
      "live O\n",
      "in O\n",
      "Berkeley B-LOC\n",
      ", O\n",
      "California B-LOC\n",
      ". O\n",
      "[SEP] O\n"
     ]
    }
   ],
   "source": [
    "inputIds = zip(encoding.input_ids.squeeze().tolist(), predicted_labels)\n",
    "print(inputIds) \n",
    "\n",
    "for id, label in zip(encoding.input_ids.squeeze().tolist(), predicted_labels):\n",
    "  print(tokenizer.decode([id]), label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
